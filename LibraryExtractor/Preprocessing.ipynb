{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'libraries'\n",
    "MAX_TOKENS = 200\n",
    "_DATA_DIR = f'../data/{DATASET_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(_DATA_DIR + '/libraries.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - filter out rows where the method name doesnt contain any of the chosen subtokens\n",
    "# classes = { 0: 'train', 1: 'save', 2: 'process', 3: 'forward', 4: 'predict' }\n",
    "\n",
    "# df = df[df.method_name.str.contains(\"|\".join(classes.values()))]\n",
    "\n",
    "# Assign categories based on method name\n",
    "# df['category'] = df.method_name.map(lambda x: np.array([x.find(s) for s in classes.values()]).argmax())\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_name(path):\n",
    "    s = path.split('/')\n",
    "    return f\"{s[5]}--{s[6]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get unique libraries\n",
    "df['libraries'] = df.references.map(lambda x: list(set([s.split('.')[0] for s in x])))\n",
    "# df['references'] = df['references'].apply(lambda x: list(set(x))) # Dont store duplicates\n",
    "df['references'] = df['references'].apply(lambda x: x if len(x) <= MAX_TOKENS else random.sample(x, MAX_TOKENS))\n",
    "df['project'] = df.file.map(lambda x: get_project_name(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Briefly inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(np.concatenate(df.libraries.values).ravel(), columns=['library'])\n",
    "stats.head()\n",
    "stats['count'] = stats.groupby('library')['library'].transform('count')\n",
    "stats = stats.drop_duplicates(subset=['library']).sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports = np.concatenate(df.references.values).ravel()\n",
    "print(f\"Total number of methods {len(df)}\\nNumber of unique method names {len(np.unique(df.method_name))}\")\n",
    "print(f\"Total number of libraries {len(stats)}\\nTotal number of import references {len(imports)}\\nTotal number of unique import references {len(np.unique(imports))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate libraries by project name\n",
    "project_libraries = df.groupby(['project'])['libraries'].sum().map(lambda x: list(set(x)))\n",
    "project_libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check frequency of libraries\n",
    "df_proj_libs = pd.DataFrame(np.concatenate(project_libraries).ravel(), columns=['library'])\n",
    "df_proj_libs['count'] = df_proj_libs.groupby('library')['library'].transform('count')\n",
    "df_proj_libs = df_proj_libs.drop_duplicates(subset=['library']).sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "df_proj_libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get all libraries when are referenced > 1 (i.e. not project specific)\n",
    "shared_project_libraries = df_proj_libs[df_proj_libs['count'] > 1]\n",
    "print(f\"{len(shared_project_libraries)} out of {len(stats)} declared libraries are project specific ({len(shared_project_libraries) / len(stats):.2f}%)\")\n",
    "shared_libs = list(shared_project_libraries.library)\n",
    "shared_project_libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def camel_case_split(identifier, joinToken):\n",
    "    matches = re.finditer(\n",
    "        '.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)',\n",
    "        identifier,\n",
    "    )\n",
    "    return f'{joinToken}'.join([m.group(0).lower() for m in matches])\n",
    "\n",
    "def snake_case_split(identifier, joinToken):\n",
    "    return f'{joinToken}'.join([x for x in identifier.split('_') if x != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_processed = df.copy()\n",
    "# Drop all library references that are project specific\n",
    "df_processed['references'] = df_processed['references'].apply(lambda x: [s for s in x if s.split('.')[0] in shared_libs])\n",
    "df_processed['libraries'] = df_processed['libraries'].apply(lambda x: [s for s in x if s in shared_libs])\n",
    "# Some rows may now include no references - drop these\n",
    "df_processed = df_processed[~df_processed.references.str.len().eq(0)]\n",
    "df_processed['references'] = df_processed['references'].apply(lambda x: \",\".join(x))\n",
    "\n",
    "# split camel/snake case method names\n",
    "df_processed['method_name'] = df_processed.method_name.map(lambda x: snake_case_split(x, '|'))\n",
    "df_processed['method_name'] = df_processed.method_name.map(lambda x: camel_case_split(x, '|'))\n",
    "\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df_processed['references'].str.split(',').values\n",
    "\n",
    "num_tokens_per_method = [len(l) for l in tokens]\n",
    "print(f\"Max number of tokens in method {np.max(num_tokens_per_method)}\\nMin number of tokens in a method {np.min(num_tokens_per_method)}\\nAverage number of tokens per method {np.mean(num_tokens_per_method):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique method names: {len(np.unique(df_processed.method_name))}\\nNumber of unique tokens {len(np.unique(tokens))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_processed = df_processed.method_name.to_frame().merge(df_processed.references, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Partition into sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size, test_size = 0.9, 0.05, 0.05\n",
    "train, remainder = train_test_split(df_processed, test_size=(1-train_size), shuffle=True)\n",
    "validate, test =  train_test_split(remainder, test_size=test_size/(test_size + val_size))\n",
    "\n",
    "print(f\"{len(train)} train samples\\n{len(validate)} validation samples\\n{len(test)} test samples\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique method names: {len(np.unique(train.method_name))}\\nNumber of unique tokens {len(np.unique(train['references'].str.split(',').values))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "train.to_csv(_DATA_DIR+'/train.csv', encoding='utf-8', sep=\" \", index=False, header=None, quoting = csv.QUOTE_NONE, escapechar = ' ')\n",
    "validate.to_csv(_DATA_DIR+'/val.csv', encoding='utf-8', sep=\" \", index=False, header=None, quoting = csv.QUOTE_NONE, escapechar = ' ')\n",
    "test.to_csv(_DATA_DIR+'/test.csv', encoding='utf-8', sep=\" \", index=False, header=None, quoting = csv.QUOTE_NONE, escapechar = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scc)",
   "language": "python",
   "name": "scc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
